{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# Whatever other imports you need\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import OrderedDict\n",
    "import csv \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d54589cd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tova_300.csv\")\n",
    "df.head() #the head() method is used to return top n (5 by default) rows of a data frame or series.\n",
    "sns.countplot(x = 'Author', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    #divide the input df into a test df and a train df by splitting the df where the 'test' starts:\n",
    "    #test_row_starting_index = df.loc[df['Type'] == 'test']\n",
    "    #train_df = df.iloc[:2343]\n",
    "    #test_df = df.iloc[2343:]\n",
    "    #return train_df.to_csv(\"train_df.csv\", index=False), test_df.to_csv(\"test_df.csv\", index=False) \n",
    "    train_df = df[df[\"Type\"] == \"train\"]\n",
    "    test_df = df[df[\"Type\"] == \"test\"]\n",
    "    test_df.reset_index(inplace=True, drop=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = np.random.RandomState()\n",
    "\n",
    "def sample(dt):\n",
    "    d = dt.sample(n=2, random_state=rd)  #sample() returns  a random sample of items from an axis of object\n",
    "                                        #n=number of items from axis to return\n",
    "    doc1 = d.iloc[0].values.tolist()\n",
    "    doc2 = d.iloc[1].values.tolist()\n",
    "    \n",
    "    if doc1[-1] == doc2[-1]: \n",
    "        return (doc1[:-1], doc2[:-1], 1)\n",
    "    else:\n",
    "        return (doc1[:-1], doc2[:-1], 0)\n",
    "        \n",
    "def build_samples(dt, n= 1000):\n",
    "    sample_0 = []\n",
    "    sample_1 = []\n",
    "\n",
    "    while len(sample_1) < n or len(sample_0) <n:\n",
    "        s = sample(dt)\n",
    "        if s[2] == 1 and s not in sample_1 and len(sample_1) < n:\n",
    "            sample_1.append(s)\n",
    "        elif s[2] == 0 and s not in sample_0 and len(sample_0) < n:\n",
    "            sample_0.append(s)\n",
    "    return sample_0 + sample_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Data(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class Test_Data(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class ClassModel(nn.Module):\n",
    "    def __init__(self, input, hidden = None, nonlin = None):\n",
    "        super(ClassModel,self).__init__()\n",
    "\n",
    "        if hidden is not None:\n",
    "            self.layer_1 = nn.Linear(input, hidden)\n",
    "            self.layer_hidden = nn.Linear(hidden, hidden)\n",
    "            self.layer_out = nn.Linear(hidden, 1)\n",
    "\n",
    "        else:\n",
    "            self.layer_1 = nn.Linear(input, 64)\n",
    "            self.layer_hidden = None\n",
    "            self.layer_out = nn.Linear(64,1)\n",
    "        \n",
    "        if nonlin == 1:\n",
    "            self.nonlin = nn.ReLU()\n",
    "        else:\n",
    "            self.nonlin = nn.Softmax(dim=1)\n",
    "    def forward(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        if self.layer_hidden is not None:\n",
    "            x = self.nonlin(x)\n",
    "        x = self.layer_out(x) \n",
    "        return x\n",
    "\n",
    "def actual_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "def build_train_model(featurefile, hidden_layers=None, choice=None, should_print=True):\n",
    "    #if should_print:\n",
    "     #   print(\"Reading {}...\".format(featurefile))\n",
    "\n",
    "    df = read_file_df(featurefile)\n",
    "\n",
    "    #train = df[df.columns.difference(['target'])][df['target'] == 'train']\n",
    "    #test = df[df.columns.difference(['target'])][df['target'] == 'test']\n",
    "    train, test = split_df(df)\n",
    "\n",
    "    train_samples = shuffle(build_samples(train, 1600))\n",
    "    test_samples = shuffle(build_samples(test, 400))\n",
    "    \n",
    "    X_train = np.array([v[0] + v[1] for v in train_samples])\n",
    "    X_test = np.array([v[0] + v[1] for v in test_samples]) \n",
    "    y_train = np.array([v[2] for v in train_samples])\n",
    "    y_test = np.array([v[2] for v in test_samples])\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # X_train = scaler.fit_transform(X_train)\n",
    "    # # X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    epochs = 30\n",
    "    batch_size = 32 \n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_data = Train_Data(torch.FloatTensor(X_train),\n",
    "                        torch.FloatTensor(y_train))\n",
    "\n",
    "    test_data = Test_Data(torch.FloatTensor(X_test))\n",
    "    train_load  = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_load = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ClassModel(X_train.shape[1], hidden_layers, choice)\n",
    "    model.to(device)\n",
    "    if should_print:\n",
    "        print(model)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate) # stochastic optim \n",
    "\n",
    "    # model.train()\n",
    "    \n",
    "    for e in range(1, epochs+1):  \n",
    "        epochs_l = 0\n",
    "        epochs_acc = 0\n",
    "        for batch in train_load: \n",
    "            model.train()\n",
    "            X_batch, y_batch = batch \n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_batch = torch.unsqueeze(y_batch, 1)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            \n",
    "            l = criterion(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = actual_acc(y_pred, y_batch)\n",
    "            epochs_l += l.item()\n",
    "            epochs_acc += acc.item()    \n",
    "\n",
    "        if should_print:\n",
    "            print(\"Epoch {}:  |  Loss: {}:  |  Accuracy: {}\".format(e, epochs_l/len(train_load), epochs_acc/len(train_load)))\n",
    "    \n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    y_pred_bonus = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_load:\n",
    "            X_batch = X_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "           \n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            y_pred_b = y_pred\n",
    "            y_pred_tag = torch.round(y_pred)\n",
    "            y_pred_bonus.append(y_pred_b.cpu().numpy()) \n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "    y_pred_bonus = [a.squeeze().tolist() for a in y_pred_bonus]\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    \n",
    "    r1 = classification_report(y_test, y_pred_list, output_dict=True)\n",
    "    r2 = accuracy_score(y_test, y_pred_list)\n",
    "    if should_print:\n",
    "        print(pd.DataFrame(r1), \"\\naccuracy:\", r2)\n",
    "\n",
    "    return (model, y_pred_bonus, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_train_model(\"tova_300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LILYA:\n",
    "\n",
    "def sample(dt):\n",
    "    d = dt.sample(n=2, random_state=rd)  #sample() returns  a random sample of items from an axis of object\n",
    "                                        #n=number of items from axis to return\n",
    "    doc1 = d.iloc[0].values.tolist()\n",
    "    doc2 = d.iloc[1].values.tolist()\n",
    "    \n",
    "    if doc1[-1] == doc2[-1]: \n",
    "        return (doc1[:-1], doc2[:-1], 1)\n",
    "    else:\n",
    "        return (doc1[:-1], doc2[:-1], 0)\n",
    "        \n",
    "def build_samples(dt, n= 1000):\n",
    "    sample_0 = []\n",
    "    sample_1 = []\n",
    "\n",
    "    while len(sample_1) < n or len(sample_0) <n:\n",
    "        s = sample(dt)\n",
    "        if s[2] == 1 and s not in sample_1 and len(sample_1) < n:\n",
    "            sample_1.append(s)\n",
    "        elif s[2] == 0 and s not in sample_0 and len(sample_0) < n:\n",
    "            sample_0.append(s)\n",
    "    return sample_0 + sample_1\n",
    "\n",
    "#XIAO:\n",
    "def sampler(df, batch_size=5, train=True):\n",
    "    samples= []\n",
    "    tensor_label_pairs=[]\n",
    "    trainflag = None\n",
    "    if train:\n",
    "        trainflag = 0\n",
    "    else:\n",
    "        trainflag = 1\n",
    "    for i in range(batch_size):\n",
    "        authors = list(set(df[\"author\"]))\n",
    "        seed_authors = random.choices(authors, k=2)\n",
    "        data_train = df[df[\"test_train\"] == trainflag]\n",
    "        seed_entries_1 = (data_train[data_train[\"author\"] == seed_authors[0]]).sample(n=2, replace=True)\n",
    "        seed_entries_2 = (data_train[data_train[\"author\"] == seed_authors[1]]).sample(n=2, replace=True)\n",
    "        if random.random() < 0.5:\n",
    "            samples.append((seed_entries_1.iloc[0], seed_entries_1.iloc[1],0))\n",
    "        else:\n",
    "            samples.append((seed_entries_1.iloc[0], seed_entries_2.iloc[0],1))\n",
    "    width = len(samples[0][0])-3\n",
    "    for sample in samples:\n",
    "        a = list(sample[0])[1:-2]\n",
    "        b = list(sample[1])[1:-2]\n",
    "        c = Variable(torch.Tensor((a+b)))\n",
    "        label = torch.Tensor([sample[2]])\n",
    "        tensor_label_pairs.append((c,label))\n",
    "    return tensor_label_pairs\n",
    "\n",
    "\n",
    "#YIQIAN:\n",
    "\n",
    "def sample_data(batch_size, df):\n",
    "    choices = []\n",
    "    sample= []\n",
    "    for i in range(batch_size):\n",
    "        author1 = random.choice(df.author)\n",
    "        author2 = random.choice(df.author)\n",
    "        while author1 == author2:\n",
    "            author2 = random.choice(df.author)\n",
    "        \n",
    "        seed_entries_1 = (df[df[\"author\"] == author1]).sample(n=2, replace=True)\n",
    "        seed_entries_2 = (df[df[\"author\"] == author2]).sample(n=2, replace=True)\n",
    "        if random.random() < 0.5:\n",
    "            choices.append((seed_entries_1.iloc[0], seed_entries_1.iloc[1], 0))\n",
    "        else:\n",
    "            choices.append((seed_entries_1.iloc[0], seed_entries_2.iloc[0], 1))\n",
    "\n",
    "    for choose in choices:\n",
    "        author1_data = list(choose[0])[2:]\n",
    "        author2_data = list(choose[1])[2:]\n",
    "        combine = Variable(torch.Tensor((author1_data + author2_data)))\n",
    "        index = torch.Tensor([choose[2]])\n",
    "        sample.append((combine, index))\n",
    "    return sample\n",
    "\n",
    "def pred(inputs):\n",
    "    if net(inputs) > 0.5:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "    return prediction\n",
    "    \n",
    "\n",
    "#ARI:\n",
    "\n",
    "def __sample_data(df):\n",
    "    samples = list(combinations(df.values, 2)) #what is combinations? what is 2? two vectors?\n",
    "    df = pd.DataFrame(samples) #make a pandas dataframe out of the samples\n",
    "    df = df.stack() #turn long df into short one?\n",
    "    y = [] \n",
    "    df2 = df.unstack()\n",
    "    y = df2.apply(lambda row: row[0][-1]==row[1][-1], axis=1)\n",
    "    df = df.apply(lambda row: row[1:-2])\n",
    "    df = df.unstack()\n",
    "    df.insert(0,\"class\",y)\n",
    "    \n",
    "    positive_samples = df[df[\"class\"] == True]\n",
    "    negative_samples = df[df[\"class\"] == False][:positive_samples.shape[0]]\n",
    "    samples = pd.concat([positive_samples,negative_samples])\n",
    "    return samples\n",
    "\n",
    "#FANG:\n",
    "\n",
    "def __sample_data(df):\n",
    "    #\n",
    "    samples = list(combinations(df.values, 2))\n",
    "    df = pd.DataFrame(samples)\n",
    "    df = df.stack()\n",
    "    y = []\n",
    "    df2 = df.unstack()\n",
    "    y = df2.apply(lambda row: row[0][-1]==row[1][-1], axis=1)\n",
    "    df = df.apply(lambda row: row[1:-2])\n",
    "    df = df.unstack()\n",
    "    df.insert(0,\"class\",y)\n",
    "    \n",
    "    positive_samples = df[df[\"class\"] == True]\n",
    "    negative_samples = df[df[\"class\"] == False][:positive_samples.shape[0]]\n",
    "    samples = pd.concat([positive_samples,negative_samples])\n",
    "    return samples\n",
    "\n",
    "\n",
    "#MERLE:\n",
    "\n",
    "def sample_data(size, df):\n",
    "    def compare_author(i1, i2):\n",
    "        d1_df = df[df.ID == i1]\n",
    "        d2_df = df[df.ID == i2]\n",
    "        author1 = d1_df['0']\n",
    "        a1 = author1.values.tolist()\n",
    "        author2 = d2_df['0']\n",
    "        a2 = author2.values.tolist()\n",
    "        d1 = d1_df.values.tolist()\n",
    "        d1 = d1[0][3:]\n",
    "        d2 = d2_df.values.tolist()\n",
    "        d2 = d2[0][3:]\n",
    "        if a1 == a2:\n",
    "            c = 1\n",
    "        else:\n",
    "            c = 0\n",
    "        d = d1 + d2\n",
    "        sample = (d, c)\n",
    "        return sample\n",
    "\n",
    "    samples = []\n",
    "    counter1 = 0\n",
    "    counter0 = 0\n",
    "    while len(samples) <= size:\n",
    "        index1 = random.choice(df.index)\n",
    "        index2 = random.choice(df.index)\n",
    "        while index1 == index2:\n",
    "            index2 = random.choice(df.index)\n",
    "        sample = compare_author(index1, index2)\n",
    "        if sample[1] == 1:\n",
    "            if counter1 <= size/2 + 1:\n",
    "                samples.append(sample)\n",
    "                counter1 += 1\n",
    "        else:\n",
    "            if counter0 <= size/2 + 1:\n",
    "                samples.append(sample)\n",
    "                counter0 += 1\n",
    "    random.shuffle(samples)\n",
    "    return samples\n",
    "\n",
    "#JULIA:\n",
    "     for epoch in range(epoch):\n",
    "            for i in range(samplesize):\n",
    "                in1 = random.randint(0, len(documents)-1)\n",
    "                auth = labels.iloc[in1, 0]\n",
    "                in_same = labels[labels.iloc[:, 0] == auth].index\n",
    "                in_diff = labels[labels.iloc[:, 0] != auth].index\n",
    "                coin = random.randint(0, 1)\n",
    "                if coin == 0:\n",
    "                    in2 = random.choice(in_diff)\n",
    "                if coin == 1:\n",
    "                    in2 = random.choice(in_same)\n",
    "                docs = documents.to_numpy()\n",
    "                doc1 = torch.Tensor(docs[in1])\n",
    "                doc2 = torch.Tensor(docs[in2])\n",
    "                instance = torch.cat((doc1, doc2), 0)\n",
    "                output = self.model(instance)\n",
    "                label = torch.Tensor([coin])\n",
    "                loss = criterion(output, label)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
