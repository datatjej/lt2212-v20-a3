{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Whatever other imports you need\n",
    "import csv\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(inputdir):\n",
    "    folders = glob(\"{}/*\".format(inputdir))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = []\n",
    "    corpus = []\n",
    "    email_wordfreq_dict = {}\n",
    "    for author_folder in folders:\n",
    "        print(author_folder)\n",
    "        author_specific_emails = glob(\"{}/*\".format(author_folder))\n",
    "        #author_name = author_folder[13:] #zous l√∂sning\n",
    "        for email in author_specific_emails:\n",
    "            #print(email)\n",
    "            email_content = \"\"\n",
    "            with open(email, \"r\") as email:\n",
    "                for line in email:\n",
    "                    email_content += line\n",
    "            \n",
    "                #save individual tokens from the email in a temporary list:\n",
    "                words += [word.lower() for word in email_content.split() if (word.isalpha() and word not in stop_words)]\n",
    "            \n",
    "                #filter out unique words and get their frequency count in the email:\n",
    "                unique_words, word_count=get_unique(words)\n",
    "                corpus += [word for word in unique_words if word not in corpus]\n",
    "            \n",
    "                #save email + unique_words/count in nested dictionary (\"email\" contains the whole path string\n",
    "                #from which the author class can be extracted later if needed):\n",
    "                for index, count in enumerate(word_count):\n",
    "                    if email in email_wordfreq_dict:\n",
    "                        email_wordfreq_dict[email][unique_words[index]]=count\n",
    "                    else: \n",
    "                        email_wordfreq_dict[email]={}\n",
    "                        email_wordfreq_dict[email][unique_words[index]]=count\n",
    "    \n",
    "    return print(len(corpus))\n",
    "\n",
    "def get_unique(x):\n",
    "    y, f = np.unique(x, return_counts=True)\n",
    "    return y, f\n",
    "\n",
    "data_load(\"enron_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ndarray(email_wordfreq_dict):  \n",
    "    features = np.zeros((len(rows), len(index_dict))) # instantiate empty ndarray\n",
    "    for n, dict in enumerate(rows):\n",
    "        for ind, val in dict.items():\n",
    "            features[n, ind] = val # replace zeros by counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
